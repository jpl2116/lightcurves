Python Programming Class - Final Project Proposal

Motivation
As part of my academic research, I analyze astronomical light curves. One aspect of light curves I study is how functions of these light curves (such as Lomb Scargle features) change as the number of flux measurements changes for a given curve. This process is termed 'noisification'. So far I have been noisifying light curves by taking curves stored in VOSource xml format, deleting or otherwise perturbing the flux measurements stored in those files, saving a new version of the original file, and then generating L-S and other features on the new file by connecting my code with code written by members of the Transient Classification Pipeline (TCP) project. This approach worked moderately well when dealing with about 1000 light curves collected from several databases, but there are some major problems. First the data about how the light curve is noisified is stored in the file title - not the best place to keep meta data. Second, with the original and noisified versions of a light curve stored in different files their link to each other is tenuous. Finally, 1000 clean light curves may generate around 16,000 noisified light curves which may take minutes to hours to derive features from. Upcoming data sets (All Sky Automated Survey) that I will analyze will have around 10,000 clean curves which will produce on the order of 100,000 noisified curves. Deriving features for all of the curves will take many hours to days on a single processor.

Project Description
I plan to construct an sqllite database to store and keep track of astronomical light curves. Python code will ingest light curves stored in VOSource xml format (will use Beautiful Soup for xml parsing), and store each curve as a new entry. Columns in the database will keep track of curve meta data. The data base will connect with existing code to noisify light curves in a variety of manners. Noisified light curves can be stored in the database and linked back to the clean curves using meta data. The database will be connected to TCP code so that features of the curves may be derived. This will be done in a parallel manner so derivations of features for a large number of curves can be done efficiently. The derived features will be stored in the database as well, ensuring that the raw light curves and the derived features are closely linked. I will write functions for outputting sets of curves in .arff format so subsequent analysis of light curve features may easily be performed in weka or R. Further I will write functions to output curves in VOsource xml format.

